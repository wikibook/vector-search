{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers elasticsearch \n",
    "\n",
    "import numpy as np \n",
    "from transformers import AutoTokenizer, AutoModel \n",
    "from elasticsearch import Elasticsearch \n",
    "import torch \n",
    "\n",
    "# 인증정보를 사용해 일래스틱서치 접속 정보 정의\n",
    "es = Elasticsearch(\n",
    "    ['https://host:port'],\n",
    "    http_auth=('username', 'password'),\n",
    "    verify_certs=False\n",
    ")\n",
    " \n",
    "# 데이터를 저장할 인덱스의 매핑 정의\n",
    "mapping = { \n",
    "    'properties': { \n",
    "        'embedding': { \n",
    "            'type': 'dense_vector', \n",
    "            'dims': 768, # Ddense vector field의 차원을 정의합니다. \n",
    "            'index': 'true',\n",
    "            \"similarity\": \"cosine\"\n",
    "        } \n",
    "    } \n",
    "} \n",
    "\n",
    "# 정의한 매핑으로 인덱스 생성\n",
    "es.indices.create(index='jokes-index', body={'mappings': mapping}) \n",
    "\n",
    "# 색인 할 유머 데이터 세트 구성\n",
    "jokes = [ \n",
    "    { \n",
    "        'text': 'Why do cats make terrible storytellers? Because they only have one tail.', \n",
    "        'category': 'cat' \n",
    "    }, \n",
    "    { \n",
    "        'text': 'What did the cat say when he lost all his money? I am paw.', \n",
    "        'category': 'cat' \n",
    "    }, \n",
    "    { \n",
    "        'text': 'Why don\\'t cats play poker in the jungle? Too many cheetahs.', \n",
    "        'category': 'cat' \n",
    "    },\n",
    "    { \n",
    "        'text': 'Why did the tomato turn red? Because it saw the salad dressing!', \n",
    "        'category': 'vegetable' \n",
    "    },\n",
    "    { \n",
    "        'text': 'Why did the scarecrow win an award? Because he was outstanding in his field.', \n",
    "        'category': 'farm' \n",
    "    },\n",
    "    { \n",
    "        'text': 'Why did the hipster burn his tongue? Because he drank his coffee before it was cool.', \n",
    "        'category': 'hipster' \n",
    "    },    \n",
    "    {\n",
    "        'text': 'Why did the tomato turn red? Because it saw the salad dressing!', \n",
    "        'category': 'food' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the scarecrow win an award? Because he was out-standing in his field!', \n",
    "        'category': 'puns' \n",
    "    },\n",
    "    {\n",
    "        'text': 'What do you call a fake noodle? An impasta!', \n",
    "        'category': 'food' \n",
    "    },\n",
    "    {\n",
    "        'text': 'What do you call a belt made out of watches? A waist of time!', \n",
    "        'category': 'puns' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the math book look sad? Because it had too many problems!', \n",
    "        'category': 'math' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the gym close down? It just didn\\'t work out!', \n",
    "        'category': 'exercise' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why don\\'t scientists trust atoms? Because they make up everything!', \n",
    "        'category': 'science' \n",
    "    },\n",
    "    {\n",
    "        'text': 'What do you call a fake noodle? An impasta!', \n",
    "        'category': 'food' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the chicken cross the playground? To get to the other slide!', \n",
    "        'category': 'kids' \n",
    "    },\n",
    "    {\n",
    "        'text': 'Why did the frog call his insurance company? He had a jump in his car!', \n",
    "        'category': 'puns' \n",
    "    }\n",
    "\n",
    "] \n",
    "\n",
    "# BERT 토크나이저와 모델 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') \n",
    "model = AutoModel.from_pretrained('bert-base-uncased') \n",
    "\n",
    "# BERT를 활용하여 유머 데이터에 대한 임베딩 생성\n",
    "for joke in jokes: \n",
    "    text = joke['text'] \n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True) \n",
    "    with torch.no_grad(): \n",
    "        output = model(**inputs).last_hidden_state.mean(dim=1).squeeze(0).numpy() \n",
    "        joke['embedding'] = output.tolist() \n",
    "\n",
    "# 일래스틱서치에 유머 데이터 색인\n",
    "for joke in jokes: \n",
    "    es.index(index='jokes-index', body=joke) \n",
    "\n",
    "# 질의 벡터 생성\n",
    "# 질의 텍스트를 정의하고 BERT를 활용해 질의 텍스트를 벡터로 변환\n",
    "query = \"What do you get when you cross a snowman and a shark?\"\n",
    "inputs = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs).last_hidden_state.mean(dim=1).squeeze(0).numpy()\n",
    "query_vector = output\n",
    "\n",
    "# 일래스틱서치 kNN 검색 쿼리 정의\n",
    "search = {\n",
    "    \"knn\": {\n",
    "        \"field\": \"embedding\",\n",
    "        \"query_vector\": query_vector.tolist(),\n",
    "        \"k\": 3,\n",
    "        \"num_candidates\": 100\n",
    "    },\n",
    "    \"fields\": [ \"text\" ]\n",
    "}\n",
    "\n",
    "# kNN 검색 수행 및 결과 출력\n",
    "response = es.search(index='jokes-index', body=search)\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Joke: {hit['_source']['text']}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
